事务就事务就是一段sql 语句的批处理。他要么成功，要么就是失败
有4条性质
原子性(Atomic)：事务必须是原子工作单元；对于其数据修改，要么全都执行，要么全都不执行。通常，与某个事务关联的操作具有共同的目标，并且是相互依赖的。如果系统只执行这些操作的一个子集，则可能会破坏事务的总体目标。原子性消除了系统处理操作子集的可能性。

一致性(Consistency)：事务的一致性指的是在一个事务执行之前和执行之后数据库都必须处于一致性状态。这种特性称为事务的一致性。假如数据库的状态满足所有的完整性约束，就说该数据库是一致的。

隔离性(Isolation)：由并发事务所作的修改必须与任何其它并发事务所作的修改隔离。事务查看数据时数据所处的状态，到底是另一个事务执行之前的状态还是中间某个状态，相互之间存在什么影响，是可以通过隔离级别的设置来控制的。

持久性(Durability)：事务结束后，事务处理的结果必须能够得到固化，即写入数据库文件中即使机器宕机数据也不会丢失，它对于系统的影响是永久性的。


不对事务进行维护的时候会造成很多问题比如
第一类丢失更新（Update Lost）：此种更新丢失是因为回滚的原因，所以也叫回滚丢失。此时两个事务同时更新count，两个事务都读取到100
，事务一更新成功并提交，count=100+1=101，事务二出于某种原因更新失败了，然后回滚，事务二就把count还原为它一开始读到的100，此时事务一的更新就这样丢失了。

脏读（Dirty Read）：此种异常时因为一个事务读取了另一个事务修改了但是未提交的数据。
举个例子，事务一更新了count=101，但是没有提交，事务二此时读取count，值为101而不是100，然后事务一出于某种原因回滚了，然后第二个事务读取的这个值就是噩梦的开始。

不可重复读（Not Repeatable Read）：此种异常是一个事务对同一行数据执行了两次或更多次查询，但是却得到了不同的结果，也就是在一个事务里面你不能重复（即多次）读取一行数据，
如果你这么做了，不能保证每次读取的结果是一样的，有可能一样有可能不一样。造成这个结果是在两次查询之间有别的事务对该行数据做了更新操作。举个例子，事务一先查询了count，值为100，
此时事务二更新了count=101，事务一再次读取count,值就会变成101，两次读取结果不一样。

第二类丢失更新（Second Update Lost）：此种更新丢失是因为更新被其他事务给覆盖了，也可以叫覆盖丢失
。举个例子，两个事务同时更新count，都读取100这个初始值，事务一先更新成功并提交，count=100+1=101，
事务二后更新成功并提交，count=100+1=101,由于事务二count还是从100开始增加，事务一的更新就这样丢失了。
简而言之就是同时做，但是因为同时一起从100+1，导致有一个组的+1是无效的

幻读（Phantom Read）：幻读和不可重复读有点像，只是针对的不是数据的值而是数据的数量。
此种异常是一个事务在两次查询的过程中数据的数量不同，让人以为发生幻觉，幻读大概就是这么得来的吧。
举个例子，事务一查询order表有多少条记录，事务二新增了一条记录，然后事务一查了一下order表有多少记录，发现和第一次不一样，这就是幻读。


所以为了解决这么多问题，我们引入了锁
注意上面的多数情况都是两个或者多个事务相互影响，这说明假如我们能以一定的办法去分开这些纠缠在一起的事务的话也许可以解决
那么解决也分轻重缓急，不一定100%解决，也不一定完全解决不了，所以根据降低这个相互影响的级别有了数据库的隔离级别


  1.读未提交（Read Uncommitted）
  顾名思义，读取了但是没有提交，别的事务依然可以读取 所以  没有安全性可言，基本不会使用。
  2.读已提交（Read Committed）
  就是能读已经提交的，而已经提交的就是过去式了根据我们上面说的持久性，提交过的就不能进行回滚了
  ，所以消除了脏读和第一类丢失更新，这是大多数数据库的默认隔离级别，如Oracle,Sqlserver
3.可重复读（Repeatable Read）：
可重复读的意思不是说一堆事务一起读取，那样不就会造成第二类丢失了嘛，他的意思是一个事务反复读取确认，就是强迫症，他一定要确定好门到底关没有关
除了不可重复读和第二类更新丢失，这是Mysql数据库的默认隔离级别
4.串行化（Serializable）
意思是说这个事务执行的时候不允许别的事务并发执行.就是只许州官放火不许百姓点灯
完全串行化的读，只要存在读就禁止写,但可以同时读，
消除了幻读。这是事务隔离的最高级别，虽然最安全最省心，但是效率太低，一般不会用



级别\异常	第一类更新丢失	脏读	不可重复读	第二类丢失更新	幻读
读未提交	  Y	          Y	     Y	         Y	        Y
读已提交	  N	          N	     Y	         Y	        Y
可重复读	  N           N	     N	         N   	      Y
串行化   	N	          N	      N	          N	         N



那么接下来该说说什么是锁了，早在多线程的时候就有锁的身影
那么在数据库层级有两种锁
一个是悲观锁，一个是乐观锁，
悲观锁一般就是我们通常说的数据库锁机制，相当于人机
乐观锁一般是指用户自己实现的一种锁机制，相当于人人


那么先来说一下悲观锁
悲观锁有三种{
1.共享锁（Share locks简记为S锁 ‘忠贞锁’）：或者称为读锁
根据名字来记忆即可，共享就是大家一起用，事务a对你上锁，事务b也对你上锁，所以相当于你身上的锁共享你自己，而且因为共享，事务不能再给别人其他人上锁
因为只可以允许多个事务一起读你，但是不能写你，直到A释放S锁。士可杀不可辱，所以被称为读锁，当然你细品，叫忠贞锁合适不合适

2.排它锁（Exclusivelocks简记为X锁 ‘霸道锁’）：也称写锁，事务A对你加X锁以后，其他事务不能对你加任何锁，只有事务A可以读写你直到A释放X锁。

3.更新锁（简记为U锁）：用来预定要对此对象施加X锁，它允许其他事务读，但不允许再施加U锁或X锁；
当被读取的对象将要被更新时，则升级为X锁，主要是用来防止死锁的。
因为使用共享锁时，修改数据的操作分为两步，首先获得一个共享锁，读取数据，然后将共享锁升级为排它锁，然后再执行修改操作。
这样如果同时有两个或多个事务同时对一个对象申请了共享锁，在修改数据的时候，这些事务都要将共享锁升级为排它锁。这些事务都不会释放共享锁而是一直等待对方释放，这样就造成了死锁。
如果一个数据在修改前直接申请更新锁，在数据修改的时候再升级为排它锁，就可以避免死锁

简而言之，我们从先读开始，一堆事务开始读取你，并给你套索，但是不可能一直读吧，总得有点写的操作，因为读锁不能写，所以他要升级，但是呢，如果这时候好多事务一起要更新数据时
就会面临要一起升级锁，但是呢我们读锁有一个原则，就是必须等待事务先释放锁才能开始升级，你不让我不让你，大家都别升级。这时解决着这种情况，
要求让他不先升级为读锁，而选择曲线救国，先变成更新锁，那么这时候僵持的情况就得以缓解


悲观锁按照作用范围划分：

行锁：锁的作用范围是行级别，数据库能够确定那些行需要锁的情况下使用行锁，如果不知道会影响哪些行的时候就会使用表锁。
举个例子，一个用户表user，有主键id和用户生日birthday当你使用update … where id=?这样的语句数据库明确知道会影响哪一行，
它就会使用行锁，当你使用update … where birthday=?这样的的语句的时候因为事先不知道会影响哪些行就可能会使用表锁。
简而言之就是只要你的id的话就对着id找，啥也不知道就得全盘遍历
表锁：锁的作用范围是整张表。




最后就是乐观锁了
乐观锁就是相当于一个特别幸运且乐观的人，他不相信会死锁，因为他觉得操作的时候是不可能杀出来一个程咬金要对这被操作的数据进行修改，所以没必要加锁
但是在更新的时候会去判断在此期间数据有没有被修改，需要用户自己去实现。

那么这玩意有什么用呢，好像上面说的锁已经够牛逼的了，这玩意还乐观的艰辛自己的操作不会被加塞，这不是神经病嘛，有什么存在的必要吗

存在即合理，他的出现身影在读远远大于写的时候，就可以考虑用乐观锁，因为读远大于写，虽说写站少数，但还是存在，所以不管他有多么的少，只要有就
一定得有人变成更新锁，我们上面可是说了，更新锁可是不允许再施加U锁或X锁，那么这种情况就是一个老鼠屎坏了一锅粥，假如只有一个
写，那么依然要有人做出贡献变成更新锁，既然更新锁出现了，那么数量庞大的读取就一定会深受影响。




